{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNA PROBLEM\n",
    "The high-level solution is presented in thress simple steps:\n",
    "\n",
    "1) Read FASTA input data and create an RDD[String], where each RDD element is a FASTA record (it can be either a comment line or an actual DNA sequence)\n",
    "\n",
    "2) Define a mapper function: for every DNA letter in a FASTA record, emit a pair of (dna_letter, 1) where dna_letter is in {A, T, C, G} and 1 is a frequency (similar to a word count solution)\n",
    "\n",
    "3) Sum up frequencies for all DNA letters (this is a reduction step). For each unique dna_letter, group and add all frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Create an RDD of String from Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark= SparkSession.builder \\\n",
    "    .appName(\"dna-base-rdd\")    \\\n",
    "    .master(\"local\")    \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "input_path = \"C:/Users/malam/development/data/spark/sample.fasta\"\n",
    "records_rdd = spark.read \\\n",
    "    .text(input_path)   \\\n",
    "    .rdd.map(lambda r: r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['>seq1',\n",
       " 'cGTAaccaataaaaaaacaagcttaacctaattc',\n",
       " '>seq2',\n",
       " 'agcttagTTTGGatctggccgggg',\n",
       " '>seq3',\n",
       " 'gcggatttactcCCCCCAAAAANNaggggagagcccagataaatggagtctgtgcgtccaca',\n",
       " 'gaattcgcacca',\n",
       " 'AATAAAACCTCACCCAT',\n",
       " 'agagcccagaatttactcCCC',\n",
       " '>seq4',\n",
       " 'gcggatttactcaggggagagcccagGGataaatggagtctgtgcgtccaca',\n",
       " 'gaattcgcacca']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Define a Mapper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_FASTA_record(fasta_record):\n",
    "    key_value_list = [] \n",
    "    if (fasta_record.startswith(\">\")):\n",
    "        # z counts the number of FASTA sequences\n",
    "        key_value_list.append((\"z\", 1))\n",
    "    else:\n",
    "        chars = fasta_record.lower()\n",
    "        for c in chars:\n",
    "            key_value_list.append((c, 1))\n",
    "    print(key_value_list) \n",
    "    return key_value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_rdd = records_rdd.flatMap(lambda rec: process_FASTA_record(rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Find Frequencies of DNA Letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies_rdd = pairs_rdd.reduceByKey(lambda x, y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('z', 4), ('c', 61), ('g', 53), ('t', 45), ('a', 73), ('n', 2)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'z': 4, 'c': 61, 'g': 53, 't': 45, 'a': 73, 'n': 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies_rdd.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('z', 4), ('c', 61), ('g', 53), ('t', 45), ('a', 73), ('n', 2)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_rdd = pairs_rdd.groupByKey()\n",
    "frequencies_rdd = grouped_rdd.mapValues(lambda values : sum(values))\n",
    "frequencies_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pros:\n",
    "\n",
    "The provided solution works and is simple: uses minimal amount of code to get the job done and uses the Spark’s simple map() and reduceByKey() transformations.\n",
    "\n",
    "There is no scalability issue since we use reduceByKey() for reducing all (key, value) pairs, which will automatically perform the combine() optimization (local aggregation) on all worker nodes.\n",
    "\n",
    "Cons:\n",
    "\n",
    "This solution emits too many (key, value) pairs, where key is a DNA-letter and value is 1, as frequency. Sometimes, emitting too many (key, value) pairs might cause memory problems. If you get any error due to too many (key, value) pairs, then you might adjust the RDD’s StorageLevel. By default, Spark uses MEMORY, but you can set the StorageLevel to MEMORY and DISK combinations for that RDD.\n",
    "\n",
    "Performance is not an optimal since emitting too many (key, value) pairs will take network time and prolong the shuffle time. As during the second processing step we defined, too many single frequency tuples are emitted, network time will prove a bottleneck when scaling this solution."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9545096d6a52d4b34adce3167e4787f469b0299861bb959c27dd86fc7feca162"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pyspark': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
